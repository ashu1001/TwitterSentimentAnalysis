{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Sun Mar 02 01:31:05 +0000 2014\", \"default_profile\": true, \"description\": \"A gooner who always renew his Hotstar account in hope to see my team do well in PL and also an engineer.\", \"favourites_count\": 303, \"followers_count\": 18, \"friends_count\": 144, \"id\": 2367943692, \"id_str\": \"2367943692\", \"name\": \"Ashutosh Singh\", \"profile_background_color\": \"C0DEED\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1006423447654711297/YPAh9TF9_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1006423447654711297/YPAh9TF9_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"95ashu_s\", \"status\": {\"created_at\": \"Tue Mar 17 04:48:58 +0000 2020\", \"id\": 1239775711625383936, \"id_str\": \"1239775711625383936\", \"in_reply_to_screen_name\": \"AbijitG\", \"in_reply_to_status_id\": 1239765262645092352, \"in_reply_to_user_id\": 231122790, \"lang\": \"und\", \"source\": \"<a href=\\\"https://mobile.twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web App</a>\", \"text\": \"@AbijitG @this_vid\"}, \"statuses_count\": 50}\n"
     ]
    }
   ],
   "source": [
    "# initialize api instance\n",
    "twitter_api = twitter.Api(consumer_key='XXXXXXXXXXX',\n",
    "                        consumer_secret='XXXXXXXXXXXXXXXXXXX',\n",
    "                        access_token_key='XXXXXXXXXXXXXXX',\n",
    "                        access_token_secret='XXXXXXXXXXXXXXXX')\n",
    "\n",
    "# test authentication\n",
    "print(twitter_api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTestSet(search_keyword):\n",
    "    try:\n",
    "        tweets_fetched = twitter_api.GetSearch(search_keyword, count = 100)\n",
    "        \n",
    "        print(\"Fetched \" + str(len(tweets_fetched)) + \" tweets for the term \" + search_keyword)\n",
    "        \n",
    "        return [{\"text\":status.text, \"label\":None} for status in tweets_fetched]\n",
    "    except:\n",
    "        print(\"Unfortunately, something went wrong..\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search keyword:Really annoyed\n",
      "Fetched 100 tweets for the term Really annoyed\n",
      "[{'text': 'Whenever I read about how folks are “surprised” that women like Dr. Birx are the real power, I’m only further annoy… https://t.co/ir1gKsUgD8', 'label': None}, {'text': 'My husband made me stand here as he took this pic. I rolled my eyes and was really annoyed. I looked out the window… https://t.co/baT6Uk4DIF', 'label': None}, {'text': 'as much as elena annoyed me, i wish she didn’t leave vd): i really can’t unsee her &amp; damon together', 'label': None}, {'text': \"@GeorgeC68457786 I know some of you like them, I'm glad to hear it.\\nHowever between people annoyed by it and the fa… https://t.co/CvoygB03Ia\", 'label': None}]\n"
     ]
    }
   ],
   "source": [
    "search_term = input(\"Enter a search keyword:\")\n",
    "testDataSet = buildTestSet(search_term)\n",
    "\n",
    "print(testDataSet[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrainingSet(corpusFile, tweetDataFile):\n",
    "    import csv\n",
    "    import time\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    with open(corpusFile,'r') as csvfile:\n",
    "        lineReader = csv.reader(csvfile,delimiter=',', quotechar=\"\\\"\")\n",
    "        for row in lineReader:\n",
    "            corpus.append({\"tweet_id\":row[2], \"label\":row[1], \"topic\":row[0]})\n",
    "            \n",
    "    rate_limit = 180\n",
    "    sleep_time = 900/180\n",
    "    \n",
    "    trainingDataSet = []\n",
    "    \n",
    "    for tweet in corpus:\n",
    "        try:\n",
    "            status = twitter_api.GetStatus(tweet[\"tweet_id\"])\n",
    "            #print(\"Tweet fetched\" + status.text)\n",
    "            tweet[\"text\"] = status.text\n",
    "            trainingDataSet.append(tweet)\n",
    "            time.sleep(sleep_time) \n",
    "        except: \n",
    "            continue\n",
    "    # now we write them to the empty CSV file\n",
    "    with open(tweetDataFile,'w') as csvfile:\n",
    "        linewriter = csv.writer(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
    "        for tweet in trainingDataSet:\n",
    "            try:\n",
    "                linewriter.writerow([tweet[\"tweet_id\"], tweet[\"text\"], tweet[\"label\"], tweet[\"topic\"]])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return trainingDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusFile = \"data/corpus.csv\"\n",
    "tweetDataFile = \"data/tweetDataFile.csv\"\n",
    "\n",
    "trainingData = buildTrainingSet(corpusFile, tweetDataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER','.AT_USER','URL'])\n",
    "        \n",
    "    def processTweets(self, list_of_tweets):\n",
    "        processedTweets=[]\n",
    "        for tweet in list_of_tweets:\n",
    "            processedTweets.append((self._processTweet(tweet[\"text\"]),tweet[\"label\"]))\n",
    "        return processedTweets\n",
    "    \n",
    "    def _processTweet(self, tweet):\n",
    "        tweet = tweet.lower() # convert text to lower-case\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n",
    "        tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n",
    "        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
    "        tweet = word_tokenize(tweet) # remove repeated characters (helloooooooo into hello)\n",
    "        return [word for word in tweet if word not in self._stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetProcessor = PreProcessTweets()\n",
    "preprocessedTrainingSet = tweetProcessor.processTweets(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedTestSet = tweetProcessor.processTweets(testDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['get', 'swype', 'iphone', 'crack', 'iphone'], 'positive'),\n",
       " (['hilarious',\n",
       "   'video',\n",
       "   'guy',\n",
       "   'duet',\n",
       "   \"'s\",\n",
       "   'siri',\n",
       "   'pretty',\n",
       "   'much',\n",
       "   'sums',\n",
       "   'love',\n",
       "   'affair'],\n",
       "  'positive')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessedTrainingSet[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['whenever',\n",
       "   'read',\n",
       "   'folks',\n",
       "   '“',\n",
       "   'surprised',\n",
       "   '”',\n",
       "   'women',\n",
       "   'like',\n",
       "   'dr.',\n",
       "   'birx',\n",
       "   'real',\n",
       "   'power',\n",
       "   '’',\n",
       "   'annoy…'],\n",
       "  None),\n",
       " (['husband',\n",
       "   'made',\n",
       "   'stand',\n",
       "   'took',\n",
       "   'pic',\n",
       "   'rolled',\n",
       "   'eyes',\n",
       "   'really',\n",
       "   'annoyed',\n",
       "   'looked',\n",
       "   'window…'],\n",
       "  None)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessedTestSet[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildVocabulary(preprocessedTrainingData):\n",
    "    all_words = []\n",
    "    \n",
    "    for (words, sentiment) in preprocessedTrainingData:\n",
    "        all_words.extend(words)\n",
    "\n",
    "    wordlist = nltk.FreqDist(all_words)\n",
    "    word_features = wordlist.keys()\n",
    "    \n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet):\n",
    "    tweet_words = set(tweet)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in tweet_words)\n",
    "    return features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = buildVocabulary(preprocessedTrainingSet)\n",
    "trainingFeatures = nltk.classify.apply_features(extract_features, preprocessedTrainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBayesClassifier = nltk.NaiveBayesClassifier.train(trainingFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Negative Sentiment\n",
      "Negative Sentiment Percentage = 4.0%\n"
     ]
    }
   ],
   "source": [
    "NBResultLabels = [NBayesClassifier.classify(extract_features(tweet[0])) for tweet in preprocessedTestSet]\n",
    "\n",
    "# get the majority vote\n",
    "if NBResultLabels.count('positive') > NBResultLabels.count('negative'):\n",
    "    print(\"Overall Positive Sentiment\")\n",
    "    print(\"Positive Sentiment Percentage = \" + str(100*NBResultLabels.count('positive')/len(NBResultLabels)) + \"%\")\n",
    "else: \n",
    "    print(\"Overall Negative Sentiment\")\n",
    "    print(\"Negative Sentiment Percentage = \" + str(100*NBResultLabels.count('negative')/len(NBResultLabels)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBResultLabels.count('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBResultLabels.count('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBResultLabels.count('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
